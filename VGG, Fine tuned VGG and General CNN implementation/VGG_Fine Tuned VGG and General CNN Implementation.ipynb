{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import PIL\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation,Dropout,Flatten,Dense\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import applications\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convnet Team Impasta\n",
    "### 15 layer cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "## 3D feature maps section\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 1D flattened section\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model characteristics\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1855 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16 ## Feel free to change , a batch_size of 5 provides whole number of training and testing samples\n",
    "\n",
    "# Modifying the training dataset with minor augmentations . This technique is done to overcome the large sample cost\n",
    "datagen_train = ImageDataGenerator(rescale=1./255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True)\n",
    "#only augmentation used for testing/validation , because training is already done,only a normalization is required\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#generator function to read traniing input data\n",
    "# class_mode is set to binary , because we have 2 classes , pasta and impasta\n",
    "# all images are converted to 150x150x3 format\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "        'c:/input/train',target_size=(150, 150),batch_size=batch_size,class_mode='binary')\n",
    "\n",
    "\n",
    "#generator function to read test input data\n",
    "validation_generator =datagen_test.flow_from_directory(\n",
    "        'c:/input/validation',target_size=(150, 150),batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "115/115 [==============================] - 24s 210ms/step - loss: 0.7322 - acc: 0.5062 - val_loss: 0.6891 - val_acc: 0.5062\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 24s 207ms/step - loss: 0.6994 - acc: 0.5562 - val_loss: 0.6765 - val_acc: 0.5594\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 24s 206ms/step - loss: 0.6851 - acc: 0.5823 - val_loss: 0.6567 - val_acc: 0.5781\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 24s 205ms/step - loss: 0.6735 - acc: 0.6052 - val_loss: 0.6302 - val_acc: 0.6312\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 24s 210ms/step - loss: 0.6682 - acc: 0.5987 - val_loss: 0.6298 - val_acc: 0.6594\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 23s 204ms/step - loss: 0.6522 - acc: 0.6179 - val_loss: 0.6166 - val_acc: 0.6687\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 23s 199ms/step - loss: 0.6601 - acc: 0.6182 - val_loss: 0.6099 - val_acc: 0.6344\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 23s 199ms/step - loss: 0.6397 - acc: 0.6535 - val_loss: 0.6051 - val_acc: 0.6594\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 23s 197ms/step - loss: 0.6321 - acc: 0.6428 - val_loss: 0.5915 - val_acc: 0.6875\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 23s 196ms/step - loss: 0.6289 - acc: 0.6465 - val_loss: 0.5753 - val_acc: 0.6719\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 23s 196ms/step - loss: 0.6189 - acc: 0.6623 - val_loss: 0.5688 - val_acc: 0.6687\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 23s 199ms/step - loss: 0.6180 - acc: 0.6613 - val_loss: 0.5852 - val_acc: 0.6813\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 23s 197ms/step - loss: 0.6194 - acc: 0.6525 - val_loss: 0.5520 - val_acc: 0.7000: 0.6194  - ETA: 2s - loss: 0.62\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 23s 197ms/step - loss: 0.6139 - acc: 0.6667 - val_loss: 0.6962 - val_acc: 0.6094\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 24s 211ms/step - loss: 0.6002 - acc: 0.6818 - val_loss: 0.6230 - val_acc: 0.6312\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 23s 201ms/step - loss: 0.5988 - acc: 0.6813 - val_loss: 0.5893 - val_acc: 0.6406\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 22s 195ms/step - loss: 0.6063 - acc: 0.6781 - val_loss: 0.5501 - val_acc: 0.6906\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 22s 190ms/step - loss: 0.5928 - acc: 0.6982 - val_loss: 0.5636 - val_acc: 0.6969\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.5959 - acc: 0.6840 - val_loss: 0.5720 - val_acc: 0.7063\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 22s 187ms/step - loss: 0.5690 - acc: 0.7049 - val_loss: 0.5625 - val_acc: 0.7094\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.5786 - acc: 0.7055 - val_loss: 0.6044 - val_acc: 0.6656\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 21s 185ms/step - loss: 0.5715 - acc: 0.7102 - val_loss: 0.6003 - val_acc: 0.7000\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.5597 - acc: 0.7232 - val_loss: 0.5900 - val_acc: 0.6656\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 23s 198ms/step - loss: 0.5680 - acc: 0.7162 - val_loss: 0.4851 - val_acc: 0.7625\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 22s 191ms/step - loss: 0.5583 - acc: 0.7308 - val_loss: 0.4969 - val_acc: 0.7406\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 22s 193ms/step - loss: 0.5574 - acc: 0.7179 - val_loss: 0.5012 - val_acc: 0.7312\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 22s 193ms/step - loss: 0.5650 - acc: 0.7111 - val_loss: 0.4927 - val_acc: 0.7562\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.5415 - acc: 0.7346 - val_loss: 0.4613 - val_acc: 0.7750\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.5458 - acc: 0.7221 - val_loss: 0.5036 - val_acc: 0.7656\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.5040 - acc: 0.7612 - val_loss: 0.4633 - val_acc: 0.7438\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.5297 - acc: 0.7489 - val_loss: 0.4430 - val_acc: 0.7719\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 22s 189ms/step - loss: 0.5506 - acc: 0.7335 - val_loss: 0.5248 - val_acc: 0.7281\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 21s 185ms/step - loss: 0.5221 - acc: 0.7497 - val_loss: 0.5211 - val_acc: 0.7219\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 21s 185ms/step - loss: 0.5316 - acc: 0.7466 - val_loss: 0.4815 - val_acc: 0.7344\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 22s 188ms/step - loss: 0.5168 - acc: 0.7574 - val_loss: 0.4312 - val_acc: 0.7688\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 21s 185ms/step - loss: 0.5073 - acc: 0.7624 - val_loss: 0.7978 - val_acc: 0.6062\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 21s 187ms/step - loss: 0.5228 - acc: 0.7472 - val_loss: 0.4048 - val_acc: 0.8031\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 20s 175ms/step - loss: 0.5125 - acc: 0.7602 - val_loss: 0.5080 - val_acc: 0.7438\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 21s 182ms/step - loss: 0.5039 - acc: 0.7543 - val_loss: 0.4105 - val_acc: 0.8000\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 21s 186ms/step - loss: 0.5045 - acc: 0.7655 - val_loss: 0.4480 - val_acc: 0.7719\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 22s 196ms/step - loss: 0.4842 - acc: 0.7601 - val_loss: 0.5579 - val_acc: 0.7281\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 23s 201ms/step - loss: 0.5031 - acc: 0.7613 - val_loss: 0.7971 - val_acc: 0.6562\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 22s 193ms/step - loss: 0.4964 - acc: 0.7668 - val_loss: 0.4284 - val_acc: 0.7969\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 22s 189ms/step - loss: 0.5014 - acc: 0.7841 - val_loss: 0.3781 - val_acc: 0.8063\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 23s 200ms/step - loss: 0.4660 - acc: 0.7937 - val_loss: 0.4544 - val_acc: 0.7719\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 23s 202ms/step - loss: 0.5133 - acc: 0.7674 - val_loss: 0.4118 - val_acc: 0.7812\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 23s 202ms/step - loss: 0.4897 - acc: 0.7808 - val_loss: 0.3986 - val_acc: 0.7875\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 22s 191ms/step - loss: 0.4802 - acc: 0.7847 - val_loss: 0.3910 - val_acc: 0.8000\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 22s 193ms/step - loss: 0.4677 - acc: 0.7902 - val_loss: 0.4323 - val_acc: 0.7875\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 22s 187ms/step - loss: 0.5033 - acc: 0.7716 - val_loss: 0.3953 - val_acc: 0.8063\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model using our train and validation generators , we will use this model to run it on our test images\n",
    "model.fit_generator(\n",
    "        train_generator,steps_per_epoch=1855 // batch_size,epochs=50,validation_data=validation_generator,\n",
    "        validation_steps=320 // batch_size)\n",
    "\n",
    "model.save_weights('our_model.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('our_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "test_generator_pasta =datagen_test.flow_from_directory(\n",
    "        'c:/input/test',target_size=(150, 150),batch_size=batch_size,\n",
    "    class_mode='binary',shuffle=False)\n",
    "\n",
    "output=np.round(model.predict_generator(test_generator_pasta))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.06057250e-01]\n",
      " [1.85568437e-01]\n",
      " [6.43836483e-02]\n",
      " [2.42230475e-01]\n",
      " [3.52466434e-01]\n",
      " [1.03752531e-01]\n",
      " [6.45850673e-02]\n",
      " [6.01263106e-01]\n",
      " [7.97420368e-03]\n",
      " [9.37162578e-01]\n",
      " [3.87977391e-01]\n",
      " [4.12280619e-01]\n",
      " [2.08904445e-01]\n",
      " [6.28224984e-02]\n",
      " [6.03662193e-01]\n",
      " [1.40219675e-02]\n",
      " [6.87914550e-01]\n",
      " [8.03529397e-02]\n",
      " [1.64796913e-03]\n",
      " [4.23646629e-01]\n",
      " [1.69542320e-02]\n",
      " [4.35916036e-01]\n",
      " [7.50421123e-07]\n",
      " [3.08826327e-01]\n",
      " [3.71228973e-03]\n",
      " [5.48562050e-01]\n",
      " [2.49806136e-01]\n",
      " [1.89871684e-01]\n",
      " [5.95745519e-02]\n",
      " [1.76799744e-01]\n",
      " [2.10506911e-03]\n",
      " [7.62459561e-02]\n",
      " [5.31594753e-01]\n",
      " [2.93098912e-02]\n",
      " [3.55595052e-01]\n",
      " [1.03502974e-01]\n",
      " [4.14005555e-02]\n",
      " [1.12320885e-01]\n",
      " [4.44742948e-01]\n",
      " [1.45668332e-02]\n",
      " [7.09690332e-01]\n",
      " [4.29027043e-02]\n",
      " [1.10223051e-03]\n",
      " [6.08925940e-03]\n",
      " [3.89422238e-01]\n",
      " [1.95040017e-01]\n",
      " [8.02453458e-01]\n",
      " [8.33931491e-02]\n",
      " [3.44621709e-09]\n",
      " [8.96868855e-02]\n",
      " [3.19760680e-01]\n",
      " [1.45107672e-01]\n",
      " [3.95632838e-07]\n",
      " [8.77506018e-01]\n",
      " [1.84159368e-01]\n",
      " [1.14454429e-06]\n",
      " [5.26560903e-01]\n",
      " [8.88910368e-02]\n",
      " [1.10033602e-02]\n",
      " [3.43850076e-01]\n",
      " [2.10187663e-05]\n",
      " [2.73997664e-01]\n",
      " [3.16087008e-02]\n",
      " [3.43004731e-03]\n",
      " [2.17502475e-06]\n",
      " [2.88142413e-01]\n",
      " [9.39720019e-04]\n",
      " [2.95508206e-02]\n",
      " [3.17839235e-01]\n",
      " [1.24382059e-04]\n",
      " [1.29793838e-01]\n",
      " [2.44509690e-02]\n",
      " [1.58296317e-01]\n",
      " [4.53249775e-02]\n",
      " [7.63687253e-01]\n",
      " [4.55702186e-01]\n",
      " [1.90929025e-01]\n",
      " [4.48842719e-03]\n",
      " [7.53007531e-02]\n",
      " [1.77891944e-02]\n",
      " [2.77587771e-01]\n",
      " [9.43578184e-01]\n",
      " [3.47133636e-01]\n",
      " [6.95892930e-01]\n",
      " [7.57957220e-01]\n",
      " [2.81480998e-01]\n",
      " [7.23547339e-01]\n",
      " [5.68206012e-01]\n",
      " [9.71603870e-01]\n",
      " [2.47151107e-02]\n",
      " [7.50824809e-01]\n",
      " [8.80515218e-01]\n",
      " [7.82071710e-01]\n",
      " [5.57930112e-01]\n",
      " [8.32047164e-01]\n",
      " [5.30020356e-01]\n",
      " [7.70593941e-01]\n",
      " [5.39378762e-01]\n",
      " [6.20245114e-02]\n",
      " [4.95468736e-01]\n",
      " [9.14911404e-02]\n",
      " [4.87084359e-01]\n",
      " [5.57184696e-01]\n",
      " [1.84439600e-01]\n",
      " [4.97040123e-01]\n",
      " [5.53182466e-03]\n",
      " [6.25688493e-01]\n",
      " [8.22147131e-01]\n",
      " [9.93294537e-01]\n",
      " [6.14751160e-01]\n",
      " [2.02176776e-02]\n",
      " [4.09492105e-01]\n",
      " [5.11101246e-01]\n",
      " [5.41868150e-01]\n",
      " [3.67538720e-01]\n",
      " [9.08619404e-01]\n",
      " [1.68365762e-01]\n",
      " [6.58414960e-01]\n",
      " [4.43979383e-01]\n",
      " [6.95179760e-01]\n",
      " [4.77467418e-01]\n",
      " [8.87811333e-02]\n",
      " [5.06691813e-01]\n",
      " [4.32711005e-01]\n",
      " [1.98354080e-01]\n",
      " [6.42170787e-01]\n",
      " [5.90036094e-01]\n",
      " [6.52064145e-01]\n",
      " [6.01114690e-01]\n",
      " [5.92005193e-01]\n",
      " [1.12205103e-01]\n",
      " [4.88766074e-01]\n",
      " [9.26345229e-01]\n",
      " [9.86145794e-01]\n",
      " [2.68778801e-01]\n",
      " [2.78018236e-01]\n",
      " [3.59330803e-01]\n",
      " [9.75268602e-01]\n",
      " [4.74256396e-01]\n",
      " [6.80632591e-01]\n",
      " [1.88669696e-01]\n",
      " [5.97926557e-01]\n",
      " [9.89607751e-01]\n",
      " [4.18975651e-01]\n",
      " [7.00552881e-01]\n",
      " [9.02189255e-01]\n",
      " [9.98161137e-01]\n",
      " [5.32090366e-01]\n",
      " [7.07458436e-01]\n",
      " [6.73019528e-01]\n",
      " [7.75838792e-01]\n",
      " [4.13183570e-01]\n",
      " [9.54095364e-01]\n",
      " [6.22183561e-01]\n",
      " [7.92738199e-01]\n",
      " [9.09067035e-01]\n",
      " [6.88298702e-01]\n",
      " [6.88860893e-01]\n",
      " [5.10244966e-01]\n",
      " [8.13271701e-02]]\n"
     ]
    }
   ],
   "source": [
    "output_scores=(model.predict_generator(test_generator_pasta))\n",
    "print(output_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pretrained VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using pretrained features for conv layers and running a new fully connected training over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1855 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#using vgg16 from applciations pkg\n",
    "model =applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "# batch_size set of 5( Both to force individulaity and to be divisible by the dataset total)\n",
    "batch_size =5\n",
    "\n",
    "## creating data generators for our images\n",
    "datagen =ImageDataGenerator(rescale=1. / 255)\n",
    "generator= datagen.flow_from_directory(\n",
    "        'c:/input/train',\n",
    "        target_size=(150, 150),shuffle=False,\n",
    "        batch_size=batch_size,class_mode=None)\n",
    "\n",
    "## gathering the images run through the vgg to save it to use the info\n",
    "## later to input it into our own fully connected\n",
    "\n",
    "## these features are called bottleneck features , as they restrict the efficiency\n",
    "## as these are trained already , but in this case the images are from imagenet itself.\n",
    "train_bottleneckfeatures =model.predict_generator(generator, 1855//batch_size)\n",
    "# 1855 is the number of training images\n",
    "\n",
    "# creating a numpy array and saving it as a npy file for use later\n",
    "np.save(open('bottleneck_features_train.npy', 'wb'), train_bottleneckfeatures)\n",
    "\n",
    "## doing the same setup for valdiation data\n",
    "generator =datagen.flow_from_directory(\n",
    "        'c:/input/validation',target_size=(150, 150),\n",
    "        batch_size=batch_size,class_mode=None,shuffle=False)\n",
    "validation.bottleneckfeatures = model.predict_generator(generator, 320//batch_size)\n",
    "# also , 320 is the number of validation data\n",
    "np.save(open('bottleneck_features_validation.npy', 'wb'), validation_bottleneckfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the data from default vgg and using it as input for our modification over it\n",
    "train_data =np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "train_labels =np.array([0] * 880 + [1] * 975)\n",
    "validation_data =np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels =np.array([0] * 160 + [1] * 160)\n",
    "\n",
    "## adding modification over vgg and fitting it with a sigmoid to obtain binary classification\n",
    "model =Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:])) # interface the vgg to our fully connected layers using the output from npy file \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1855 samples, validate on 320 samples\n",
      "Epoch 1/50\n",
      "1855/1855 [==============================] - 4s 2ms/step - loss: 0.8435 - acc: 0.6388 - val_loss: 0.5405 - val_acc: 0.7281\n",
      "Epoch 2/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.6066 - acc: 0.7148 - val_loss: 0.7514 - val_acc: 0.6938\n",
      "Epoch 3/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.5620 - acc: 0.7504 - val_loss: 0.5105 - val_acc: 0.7469\n",
      "Epoch 4/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.5163 - acc: 0.7704 - val_loss: 0.4256 - val_acc: 0.7875\n",
      "Epoch 5/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.4984 - acc: 0.7849 - val_loss: 0.3551 - val_acc: 0.8500\n",
      "Epoch 6/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.4545 - acc: 0.8135 - val_loss: 0.3285 - val_acc: 0.8500\n",
      "Epoch 7/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.4336 - acc: 0.8183 - val_loss: 0.3070 - val_acc: 0.8406\n",
      "Epoch 8/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.4020 - acc: 0.8350 - val_loss: 0.2838 - val_acc: 0.8719\n",
      "Epoch 9/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.3880 - acc: 0.8447 - val_loss: 0.3039 - val_acc: 0.8688\n",
      "Epoch 10/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.3465 - acc: 0.8615 - val_loss: 0.2364 - val_acc: 0.8844\n",
      "Epoch 11/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.3297 - acc: 0.8706 - val_loss: 0.2167 - val_acc: 0.9125\n",
      "Epoch 12/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.3314 - acc: 0.8706 - val_loss: 0.2388 - val_acc: 0.8813\n",
      "Epoch 13/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.3017 - acc: 0.8868 - val_loss: 0.2120 - val_acc: 0.9125\n",
      "Epoch 14/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2941 - acc: 0.8911 - val_loss: 0.2351 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2725 - acc: 0.8954 - val_loss: 0.1368 - val_acc: 0.9469\n",
      "Epoch 16/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2524 - acc: 0.8943 - val_loss: 0.1239 - val_acc: 0.9531\n",
      "Epoch 17/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2528 - acc: 0.9078 - val_loss: 0.1420 - val_acc: 0.9438\n",
      "Epoch 18/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2409 - acc: 0.9116 - val_loss: 0.1028 - val_acc: 0.9625\n",
      "Epoch 19/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2083 - acc: 0.9321 - val_loss: 0.0900 - val_acc: 0.9719\n",
      "Epoch 20/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1997 - acc: 0.9310 - val_loss: 0.0682 - val_acc: 0.9750\n",
      "Epoch 21/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2085 - acc: 0.9305 - val_loss: 0.0796 - val_acc: 0.9719\n",
      "Epoch 22/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.2050 - acc: 0.9315 - val_loss: 0.0681 - val_acc: 0.9781\n",
      "Epoch 23/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1735 - acc: 0.9429 - val_loss: 0.0487 - val_acc: 0.9875\n",
      "Epoch 24/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1559 - acc: 0.9482 - val_loss: 0.1435 - val_acc: 0.9375\n",
      "Epoch 25/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1742 - acc: 0.9456 - val_loss: 0.0313 - val_acc: 0.9906\n",
      "Epoch 26/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1666 - acc: 0.9439 - val_loss: 0.0456 - val_acc: 0.9844\n",
      "Epoch 27/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1708 - acc: 0.9509 - val_loss: 0.0303 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1760 - acc: 0.9456 - val_loss: 0.0410 - val_acc: 0.9875\n",
      "Epoch 29/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1727 - acc: 0.9439 - val_loss: 0.0671 - val_acc: 0.9781\n",
      "Epoch 30/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1536 - acc: 0.9580 - val_loss: 0.0575 - val_acc: 0.9750\n",
      "Epoch 31/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1479 - acc: 0.9542 - val_loss: 0.0239 - val_acc: 0.9938\n",
      "Epoch 32/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1288 - acc: 0.9628 - val_loss: 0.0382 - val_acc: 0.9813\n",
      "Epoch 33/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1345 - acc: 0.9650 - val_loss: 0.0253 - val_acc: 0.9938\n",
      "Epoch 34/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1312 - acc: 0.9677 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 35/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1387 - acc: 0.9612 - val_loss: 0.0217 - val_acc: 0.9906\n",
      "Epoch 36/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1341 - acc: 0.9569 - val_loss: 0.0233 - val_acc: 0.9938\n",
      "Epoch 37/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1060 - acc: 0.9639 - val_loss: 0.0321 - val_acc: 0.9875\n",
      "Epoch 38/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1202 - acc: 0.9606 - val_loss: 0.0223 - val_acc: 0.9938\n",
      "Epoch 39/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1262 - acc: 0.9682 - val_loss: 0.0250 - val_acc: 0.9906\n",
      "Epoch 40/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1331 - acc: 0.9671 - val_loss: 0.0178 - val_acc: 0.9938\n",
      "Epoch 41/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1087 - acc: 0.9704 - val_loss: 0.0158 - val_acc: 0.9938\n",
      "Epoch 42/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.0970 - acc: 0.9704 - val_loss: 0.0156 - val_acc: 0.9938\n",
      "Epoch 43/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.0935 - acc: 0.9725 - val_loss: 0.0203 - val_acc: 0.9938\n",
      "Epoch 44/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1493 - acc: 0.9639 - val_loss: 0.0186 - val_acc: 0.9938\n",
      "Epoch 45/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.0978 - acc: 0.9714 - val_loss: 0.0224 - val_acc: 0.9906\n",
      "Epoch 46/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1006 - acc: 0.9693 - val_loss: 0.0128 - val_acc: 0.9938\n",
      "Epoch 47/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.0970 - acc: 0.9774 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 48/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.0899 - acc: 0.9768 - val_loss: 0.0176 - val_acc: 0.9938\n",
      "Epoch 49/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1120 - acc: 0.9720 - val_loss: 0.0160 - val_acc: 0.9938\n",
      "Epoch 50/50\n",
      "1855/1855 [==============================] - 3s 2ms/step - loss: 0.1184 - acc: 0.9736 - val_loss: 0.0136 - val_acc: 0.9969\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# fitting the fully connected\n",
    "model.fit(train_data, train_labels,epochs=50,batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "\n",
    "## saving the model weights for future use\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fine tuning top layers\n",
    "\n",
    "## Transfer Learning\n",
    "# We are now retraining the final convolution layer set of the convnet with specific input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'vgg16_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet',include_top=False,input_shape = (150,150,3))\n",
    "\n",
    "# replicate the fully connected layers from previous model\n",
    "top_model =Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "## Architecture Idea\n",
    "## base VGG , first 15 layers +\n",
    "## Conv layers (transfer learning)+\n",
    "## fully connected layer(transfer learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model_weights_path ='bottleneck_fc_model.h5' ## to be put in the same folder or give complete path\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "#combine the top model and base model\n",
    "model=Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "#we set the first 15 layers to retain weights , we train the rest of the model with our data\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# now train the top layers again to fit the problem statement more \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1855 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "371/371 [==============================] - 29s 77ms/step - loss: 0.6430 - acc: 0.6491 - val_loss: 0.5794 - val_acc: 0.7125\n",
      "Epoch 2/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.6344 - acc: 0.6744 - val_loss: 0.5533 - val_acc: 0.7438\n",
      "Epoch 3/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.6128 - acc: 0.6922 - val_loss: 0.5691 - val_acc: 0.7344\n",
      "Epoch 4/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.5861 - acc: 0.7127 - val_loss: 0.5254 - val_acc: 0.7656\n",
      "Epoch 5/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.5452 - acc: 0.7375 - val_loss: 0.5034 - val_acc: 0.7563\n",
      "Epoch 6/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.5559 - acc: 0.7342 - val_loss: 0.5018 - val_acc: 0.7781\n",
      "Epoch 7/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.5244 - acc: 0.7660 - val_loss: 0.4548 - val_acc: 0.7844\n",
      "Epoch 8/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.5176 - acc: 0.7601 - val_loss: 0.4170 - val_acc: 0.8188\n",
      "Epoch 9/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.4880 - acc: 0.7849 - val_loss: 0.4242 - val_acc: 0.8188\n",
      "Epoch 10/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.4608 - acc: 0.7941 - val_loss: 0.4065 - val_acc: 0.8281\n",
      "Epoch 11/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.4663 - acc: 0.7930 - val_loss: 0.4106 - val_acc: 0.8313\n",
      "Epoch 12/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.4578 - acc: 0.7908 - val_loss: 0.4029 - val_acc: 0.8094\n",
      "Epoch 13/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.4288 - acc: 0.8070 - val_loss: 0.3434 - val_acc: 0.8656\n",
      "Epoch 14/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3954 - acc: 0.8431 - val_loss: 0.3098 - val_acc: 0.8844\n",
      "Epoch 15/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.4015 - acc: 0.8447 - val_loss: 0.3039 - val_acc: 0.8813\n",
      "Epoch 16/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.4028 - acc: 0.8286 - val_loss: 0.2788 - val_acc: 0.8750\n",
      "Epoch 17/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3703 - acc: 0.8420 - val_loss: 0.2491 - val_acc: 0.9156\n",
      "Epoch 18/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3457 - acc: 0.8582 - val_loss: 0.3002 - val_acc: 0.8813\n",
      "Epoch 19/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3510 - acc: 0.8571 - val_loss: 0.2130 - val_acc: 0.9156\n",
      "Epoch 20/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.3268 - acc: 0.8695 - val_loss: 0.1837 - val_acc: 0.9438\n",
      "Epoch 21/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3175 - acc: 0.8765 - val_loss: 0.2293 - val_acc: 0.9094\n",
      "Epoch 22/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.3631 - acc: 0.8604 - val_loss: 0.5007 - val_acc: 0.8375\n",
      "Epoch 23/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.3559 - acc: 0.8491 - val_loss: 0.2007 - val_acc: 0.9250\n",
      "Epoch 24/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.2796 - acc: 0.8954 - val_loss: 0.2140 - val_acc: 0.9219\n",
      "Epoch 25/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.2963 - acc: 0.8728 - val_loss: 0.2453 - val_acc: 0.9250\n",
      "Epoch 26/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.2728 - acc: 0.8976 - val_loss: 0.1689 - val_acc: 0.9563\n",
      "Epoch 27/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.2834 - acc: 0.8938 - val_loss: 0.1983 - val_acc: 0.9375\n",
      "Epoch 28/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.2372 - acc: 0.9078 - val_loss: 0.1672 - val_acc: 0.9469\n",
      "Epoch 29/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.2209 - acc: 0.9154 - val_loss: 0.4107 - val_acc: 0.8375\n",
      "Epoch 30/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.2580 - acc: 0.9084 - val_loss: 0.1244 - val_acc: 0.9500\n",
      "Epoch 31/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.1993 - acc: 0.9245 - val_loss: 0.0922 - val_acc: 0.9594\n",
      "Epoch 32/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.2113 - acc: 0.9197 - val_loss: 0.0918 - val_acc: 0.9719\n",
      "Epoch 33/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1572 - acc: 0.9423 - val_loss: 0.0732 - val_acc: 0.9719\n",
      "Epoch 34/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1979 - acc: 0.9315 - val_loss: 0.0827 - val_acc: 0.9781\n",
      "Epoch 35/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1541 - acc: 0.9466 - val_loss: 0.0735 - val_acc: 0.9719\n",
      "Epoch 36/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.1351 - acc: 0.9509 - val_loss: 0.0476 - val_acc: 0.9844\n",
      "Epoch 37/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1234 - acc: 0.9547 - val_loss: 0.0562 - val_acc: 0.9781\n",
      "Epoch 38/50\n",
      "371/371 [==============================] - 28s 75ms/step - loss: 0.1604 - acc: 0.9450 - val_loss: 0.0647 - val_acc: 0.9875\n",
      "Epoch 39/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1170 - acc: 0.9606 - val_loss: 0.0463 - val_acc: 0.9906\n",
      "Epoch 40/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1493 - acc: 0.9482 - val_loss: 0.0700 - val_acc: 0.9844\n",
      "Epoch 41/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1238 - acc: 0.9520 - val_loss: 0.0381 - val_acc: 0.9938\n",
      "Epoch 42/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1176 - acc: 0.9628 - val_loss: 0.0453 - val_acc: 0.9844\n",
      "Epoch 43/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1665 - acc: 0.9439 - val_loss: 0.0653 - val_acc: 0.9813\n",
      "Epoch 44/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.0894 - acc: 0.9704 - val_loss: 0.0277 - val_acc: 0.9875\n",
      "Epoch 45/50\n",
      "371/371 [==============================] - 29s 77ms/step - loss: 0.0995 - acc: 0.9639 - val_loss: 0.0794 - val_acc: 0.9875\n",
      "Epoch 46/50\n",
      "371/371 [==============================] - 28s 77ms/step - loss: 0.1297 - acc: 0.9612 - val_loss: 0.0641 - val_acc: 0.9813\n",
      "Epoch 47/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.0910 - acc: 0.9693 - val_loss: 0.1040 - val_acc: 0.9594\n",
      "Epoch 48/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1233 - acc: 0.9553 - val_loss: 0.0324 - val_acc: 0.9938\n",
      "Epoch 49/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1517 - acc: 0.9569 - val_loss: 0.1028 - val_acc: 0.9531\n",
      "Epoch 50/50\n",
      "371/371 [==============================] - 28s 76ms/step - loss: 0.1285 - acc: 0.9585 - val_loss: 0.0757 - val_acc: 0.9813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29abbe5def0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "\n",
    "# Modifying the training dataset with minor augmentations.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        shear_range=0.2,zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator =train_datagen.flow_from_directory('c:/input/train',\n",
    "        target_size=(150, 150),batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory('c:/input/validation',\n",
    "        target_size=(150, 150),batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# finetuning the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1855 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=320 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the weights\n",
    "model.save_weights('finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_32 (Sequential)   (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## giving the summary of the Fine-Tuned VGG architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Prediction for test images\n",
    "\n",
    "model.load_weights('finetuned.h5')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'c:/input/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_finetune=np.round(model.predict_generator(\n",
    "        test_generator,\n",
    "        steps=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(output_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.37390668e-36]\n",
      " [7.26114035e-01]\n",
      " [9.96921957e-01]\n",
      " [4.40766526e-05]\n",
      " [7.11116854e-07]\n",
      " [9.89976765e-22]\n",
      " [6.41088382e-09]\n",
      " [3.23921588e-04]\n",
      " [9.04609077e-03]\n",
      " [6.25374675e-01]\n",
      " [3.91732341e-10]\n",
      " [9.96817052e-01]\n",
      " [1.31895911e-10]\n",
      " [3.06205481e-01]\n",
      " [9.14807975e-01]\n",
      " [6.15677399e-33]\n",
      " [2.06418753e-01]\n",
      " [4.43626307e-02]\n",
      " [8.26309612e-26]\n",
      " [4.60173624e-08]\n",
      " [7.13441405e-04]\n",
      " [2.29475634e-24]\n",
      " [5.64501097e-05]\n",
      " [2.00619985e-17]\n",
      " [8.00125301e-01]\n",
      " [8.29863489e-01]\n",
      " [3.82300501e-13]\n",
      " [1.84570354e-06]\n",
      " [9.75841999e-01]\n",
      " [2.97980709e-03]\n",
      " [1.09200031e-04]\n",
      " [2.36251130e-09]\n",
      " [9.29680599e-16]\n",
      " [3.58616337e-02]\n",
      " [1.91538945e-01]\n",
      " [1.12304169e-05]\n",
      " [7.75052488e-01]\n",
      " [1.63725895e-14]\n",
      " [1.90603808e-01]\n",
      " [6.79215640e-02]\n",
      " [1.28233477e-01]\n",
      " [4.84985912e-06]\n",
      " [1.38775402e-04]\n",
      " [0.00000000e+00]\n",
      " [7.53765285e-01]\n",
      " [1.24562018e-06]\n",
      " [5.33908665e-01]\n",
      " [1.51367989e-14]\n",
      " [2.85203714e-06]\n",
      " [8.32814097e-01]\n",
      " [2.21939786e-06]\n",
      " [9.80398618e-04]\n",
      " [1.65396938e-29]\n",
      " [5.71111366e-02]\n",
      " [9.77555260e-07]\n",
      " [3.35422607e-21]\n",
      " [2.75792410e-12]\n",
      " [1.77474340e-05]\n",
      " [2.76099033e-10]\n",
      " [1.88941377e-19]\n",
      " [5.26351929e-02]\n",
      " [6.92048658e-08]\n",
      " [3.88797431e-04]\n",
      " [3.16803153e-07]\n",
      " [5.64756453e-22]\n",
      " [2.66687959e-01]\n",
      " [7.48398251e-13]\n",
      " [2.30261758e-05]\n",
      " [4.18901622e-01]\n",
      " [4.94956324e-17]\n",
      " [3.42089606e-06]\n",
      " [1.74857268e-15]\n",
      " [8.95814132e-03]\n",
      " [1.62572460e-03]\n",
      " [9.25955951e-01]\n",
      " [3.01725123e-07]\n",
      " [1.14692844e-25]\n",
      " [2.78979927e-01]\n",
      " [1.52243392e-05]\n",
      " [4.74355244e-21]\n",
      " [4.61509526e-02]\n",
      " [8.91540527e-01]\n",
      " [1.10217761e-05]\n",
      " [9.97550189e-01]\n",
      " [8.77075791e-01]\n",
      " [9.89805758e-01]\n",
      " [9.76874173e-01]\n",
      " [9.99971032e-01]\n",
      " [3.76376122e-01]\n",
      " [7.08455350e-10]\n",
      " [6.97755337e-01]\n",
      " [8.61517131e-01]\n",
      " [9.46653068e-01]\n",
      " [8.82328629e-01]\n",
      " [6.66496763e-03]\n",
      " [7.19744265e-01]\n",
      " [5.38171470e-01]\n",
      " [8.79870534e-01]\n",
      " [8.10416162e-01]\n",
      " [9.90217328e-02]\n",
      " [1.85852859e-03]\n",
      " [8.25771332e-01]\n",
      " [8.50711465e-01]\n",
      " [8.74127895e-02]\n",
      " [9.84209001e-01]\n",
      " [1.16777355e-05]\n",
      " [3.37741803e-05]\n",
      " [9.56573904e-01]\n",
      " [9.06232059e-01]\n",
      " [8.48044381e-02]\n",
      " [6.65006638e-02]\n",
      " [9.30804431e-01]\n",
      " [9.23754275e-01]\n",
      " [8.55147559e-03]\n",
      " [9.52210724e-01]\n",
      " [4.93964791e-01]\n",
      " [4.32989782e-06]\n",
      " [9.54608619e-01]\n",
      " [6.39116671e-03]\n",
      " [9.18552577e-01]\n",
      " [8.15558195e-01]\n",
      " [2.39221886e-01]\n",
      " [9.87080157e-01]\n",
      " [1.29280806e-01]\n",
      " [8.32496941e-01]\n",
      " [2.60771606e-02]\n",
      " [9.98639762e-01]\n",
      " [1.15929732e-04]\n",
      " [2.92005390e-01]\n",
      " [8.96402478e-01]\n",
      " [1.85076159e-03]\n",
      " [2.25194707e-03]\n",
      " [9.79944944e-01]\n",
      " [8.63643289e-01]\n",
      " [7.44876742e-01]\n",
      " [9.47197974e-01]\n",
      " [9.63101804e-01]\n",
      " [9.99977708e-01]\n",
      " [9.57791507e-01]\n",
      " [8.44487429e-01]\n",
      " [8.45947444e-01]\n",
      " [9.99991536e-01]\n",
      " [9.97988939e-01]\n",
      " [9.00888920e-01]\n",
      " [6.33603253e-04]\n",
      " [6.37233863e-03]\n",
      " [9.33259547e-01]\n",
      " [9.99697924e-01]\n",
      " [9.01152790e-01]\n",
      " [8.55981648e-01]\n",
      " [9.28686619e-01]\n",
      " [9.20974195e-01]\n",
      " [9.99603570e-01]\n",
      " [7.39280701e-01]\n",
      " [9.98771489e-01]\n",
      " [8.24310899e-01]\n",
      " [9.74293649e-01]\n",
      " [9.96942580e-01]\n",
      " [7.02735841e-01]\n",
      " [3.90438467e-01]]\n"
     ]
    }
   ],
   "source": [
    "output_finescore=(model.predict_generator(\n",
    "        test_generator,\n",
    "        steps=None))\n",
    "print(output_finescore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
